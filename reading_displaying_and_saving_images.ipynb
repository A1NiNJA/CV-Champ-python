{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1HbYxwGAMoz"
      },
      "source": [
        "<div id=\"home\"></div> \n",
        "\n",
        "\n",
        " Reading, Displaying and Saving Images \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h4CEbGAoAMpA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "39aa663e-5bdd-4c74-f8d5-0a8e00b5da43"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-49cf43fec226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# library imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 135\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# library imports \n",
        "import cv2 \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot images inline in the Jupyter Notebook \n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhZvTUGPAMpE"
      },
      "source": [
        "<div id=\"loading_images\"></div> \n",
        "\n",
        "\n",
        "## Loading Images with OpenCV\n",
        "\n",
        "<div style=\"text-align: right\"><a href=\"#home\">Back to ToC</a></div> \n",
        "\n",
        "----\n",
        "\n",
        "Loading images with OpenCV is simple.  It's actually only a single line of code, but there are some things you need to look out for... like the fact that **OpenCV will import all images (grayscale or color) as having 3 channels**, so in order to read a grayscale image as only having a single channel you need to pass the arg 0 after the image location. \n",
        "\n",
        "**NOTE:** The following image formats can be read by **cv2.imread()**:\n",
        "\n",
        "* Windows bitmaps - *.bmp, *.dib (always supported)\n",
        "* JPEG files - *.jpeg, *.jpg, *.jpe (see the Notes section)\n",
        "* JPEG 2000 files - *.jp2 (see the Notes section)\n",
        "* Portable Network Graphics - *.png (see the Notes section)\n",
        "* WebP - *.webp (see the Notes section)\n",
        "* Portable image format - *.pbm, *.pgm, *.ppm (always supported)\n",
        "* Sun rasters - *.sr, *.ras (always supported)\n",
        "* TIFF files - *.tiff, *.tif (see the Notes section)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc4k9BevAMpH"
      },
      "outputs": [],
      "source": [
        "# load an image\n",
        "img = cv2.imread('images/dolphin.png')\n",
        "\n",
        "# load an image as a single channel grayscale \n",
        "img_single_channel = cv2.imread('images/dolphin.png', 0)\n",
        "\n",
        "# print some details about the images \n",
        "\n",
        "print('The shape of img_single_channel is:     {}'.format(img_single_channel.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FvwG6ufAMpK"
      },
      "source": [
        "<div id=\"displaying_images\"></div> \n",
        "\n",
        "\n",
        "## 0.0.2 Displaying Images with OpenCV\n",
        "\n",
        "<div style=\"text-align: right\"><a href=\"#home\">Back to ToC</a></div>  \n",
        "\n",
        "----\n",
        "\n",
        "#### *Warning:  The code for Displaying images using OpenCV has the tendancy to crash Jupyter Kernels.  It is supposed to be used strictly as a Python Script, that is why it's been removed from an executable code block in this Notebook.*\n",
        "\n",
        "### Let's first start by using the OpenCV .imshow() function \n",
        "\n",
        "* The **cv2.imwhow()** takes two required arguments\n",
        "    * 1st Argument --> The name of the window where the image will be displayed\n",
        "    * 2nd Argument --> The image to show\n",
        "\n",
        "    **IMPORTANT NOTE:** You can show as many images as you want at once they just have to be different window names. \n",
        "\n",
        "\n",
        "In addition to the **cv2.imshow()** function there are a few other required items to make this work correctly. \n",
        "* The first peice is the **cv2.waitKey()** function\n",
        "    * Its argument --> the time in milliseconds\n",
        "    * The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke.  It can also be set to detect specific key strokes like if key a is pressed etc.\n",
        "    * **IMPORTANT NOTE**: Besides binding keyboard events this waitKey() also processes many other GUI events, so you **MUST** use it to actually display the image.\n",
        "    \n",
        "* The second required piece of code is the **cv2.destroyAllWindows()** function\n",
        "    * This simply destroys all the windows we created. \n",
        "    * **IMPORTANT NOTE**: If you want to destroy any specific window, use the function **cv2.destroyWindow()** instead where you pass the exact window name as the argument.\n",
        "    \n",
        "---\n",
        "    \n",
        "    \n",
        "Because this code will freeze the **Jupyter Notebook Kernel** this code has been moved out of an executable code block \n",
        "\n",
        "```python \n",
        "# display the image with OpenCV imshow()\n",
        "cv2.imshow('OpenCV imshow()', img)\n",
        "\n",
        "# OpenCV waitKey() is a required keyboard binding function after imwshow()\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# destroy all windows command\n",
        "cv2.destroyAllWindows()\n",
        "```\n",
        "\n",
        "---- \n",
        "\n",
        "**IMPORTANT NOTE:** There is a special case where you can already create a window and load image to it later. In that case, you can specify whether window is resizable or not. It is done with the function cv2.namedWindow(). By default, the flag is cv2.WINDOW_AUTOSIZE. But if you specify flag to be cv2.WINDOW_NORMAL, you can resize window. It will be helpful when image is too large in dimension and adding track bar to windows.\n",
        "\n",
        "```python \n",
        "# Creating the window beforehand and loading an image into it later \n",
        "cv2.namedWindow('Named-Empty Resizable Window', cv2.WINDOW_NORMAL)\n",
        "cv2.imshow('Dolphins are awesome!',img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xox3r9QuAMpO"
      },
      "source": [
        "<div id=\"plotting_images\"></div> \n",
        "\n",
        "\n",
        "## 0.0.3 Plotting Images inline with Matplotlib\n",
        "\n",
        "<div style=\"text-align: right\"><a href=\"#home\">Back to ToC</a></div> \n",
        "\n",
        "----\n",
        "\n",
        "If you are working in a Jupyter Notebook environment plotting images with Matplotlib is the best way to display images.  You can think of images as functions, because that's exactly what they are.  They are basically just matricies or a set of matricies containing values between a set range each one referred to as a pixel.  It's because of this fact that images can be plotted just as any other funcitons can be. For the sake of plotting in this notebook we will use the Python Package Matplotlib, and more specifically the **.imshow()** function.\n",
        "\n",
        "The **plt.imshow()** function (not to be confused with the **cv2.imshow()** function) can take quite a few arguments to learn more about this function you can see the documentation <a href=\"https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.imshow.html\">Here</a>\n",
        "\n",
        "For the purposes of this tutorial, I'm only using one additional argument: \n",
        "* cmap --> This is the color mapping if this is not used in this case matplotlib will try to plot the gray images as a RGB image because it has a depth of 3 channels without the 0 passed in cv2.imread() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59Wa0JVeAMpQ"
      },
      "outputs": [],
      "source": [
        "# first read in the image using OpenCV\n",
        "img = cv2.imread('images/dolphin.png')\n",
        "\n",
        "# Adding a title to the Plot \n",
        "plt.title('Monochormatic Images in Matplotlib')\n",
        "\n",
        "# Using the plt.imshow() to add the image plot to the matplotlib figure \n",
        "plt.imshow(img, cmap='gray')\n",
        "\n",
        "# This just hides x and y tick values by passing in empty lists to make the output a little cleaner \n",
        "plt.xticks([]), plt.yticks([]) \n",
        "plt.show()\n",
        "\n",
        "# print information about the image size and type \n",
        "height, width, depth = img.shape\n",
        "print('Image Width: {}px, Image Height: {}px, Image Depth: {}ch'.format(width, height, depth))\n",
        "print('Image Type: {}'.format(type(img))) # openCV stores images as np.ndarray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajlWHIXSAMpS"
      },
      "source": [
        "### Okay, let's try to plot a color image. \n",
        "\n",
        "Hmm, something doesn't look quite right in the cell below. That's because Color images loaded by default in OpenCV are in BGR (blue, green, red) mode. However, Matplotlib displays images in RGB mode. Therefore color images will not be displayed correctly in Matplotlib if image is read with OpenCV and plotted directly using Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry8u6B6lAMpU"
      },
      "outputs": [],
      "source": [
        "# Example of how matplotlib displays color images from OpenCV incorrectly\n",
        "img_color = cv2.imread('images/fruit.png')\n",
        "plt.title('How OpenCV images (BGR) display in Matplotlib (RGB)')\n",
        "plt.imshow(img_color)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW8CkDTYAMpX"
      },
      "source": [
        "Okay, let's see some ways of handling this little hicup.  Below I've outlined two options, these are obviously not the only options, but options nonetheless. \n",
        "\n",
        "### The way to plot OpenCV color images Correctly - Option 1\n",
        "The first option is to use the built in OpenCV color space conversion variable flags.  For our case we want to convert from BGR (Blue, Green, Red) colorspace to RGB (Red, Green, Blue) to do this we can use the **cv2.cvtColor()** function pass in the image and the **cv2.COLOR_BGR2RGB** variable flag "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAx7U6RzAMpZ"
      },
      "outputs": [],
      "source": [
        "# Option #1 convert the color using cv2.COLOR_BGR2RGB\n",
        "img_rgb = cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB)\n",
        "plt.title('Correct Display after converting with cv2.COLOR_BGR2RGB')\n",
        "\n",
        "# Tip: passing in empty lists for xticks & yticks will turn off \n",
        "plt.imshow(img_rgb), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzvtxAR_AMpa"
      },
      "source": [
        "### The way to plot OpenCV color images Correctly - Option 2\n",
        "Remember when I said images are functions?  Well if you kept that in mind you may have already thought of this method on your own.  What I'm referring to here is to using the fact that images are stored as numpy arrays to manually move the channels of the image matrix by slicing operations. \n",
        "\n",
        "Let's explain the meat and potatoes of this code here:\n",
        "\n",
        "```python \n",
        "img_rgb_numpy = img_color[:,:,::-1]\n",
        "```\n",
        "\n",
        "Remember that images are arrays of width, height, and depth.  For our particular example the depth is a BGR ordering, so what's exactly happening here?  Basically we leave the width and height the same by slicing all indicies with the colon (:), as for the depth, well we are just reversing its order:  BGR reversed is RGB! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rk6qo9wAMpb"
      },
      "outputs": [],
      "source": [
        "# Reverse the color porition of the image array \n",
        "img_rgb_numpy = img_color[:,:,::-1]\n",
        "plt.title('Correct Display after matrix slicing the Numpy Array')\n",
        "plt.imshow(img_rgb_numpy), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzgpeSBaAMpc"
      },
      "source": [
        "<div id=\"saving_images\"></div> \n",
        "\n",
        "\n",
        "\n",
        "## 0.0.4 Saving Images with OpenCV\n",
        "\n",
        "<div style=\"text-align: right\"><a href=\"#home\">Back to ToC</a></div> \n",
        "\n",
        "----\n",
        "\n",
        "Saving images with OpenCV is done with the **cv2.imwrite()** function.  This function takes a relative or absolute path where you want to save the image and the image you want to save. \n",
        "\n",
        "If you want to try everything we learned together, here's some code you can try from a Python script. \n",
        "\n",
        "```python\n",
        "# Saving an Image on a key press \n",
        "img = cv2.imread('images/dolphin.png')\n",
        "cv2.imshow('Option to Save image', img)\n",
        "print(\"press 's' to save the image as dolphin_3.png\\n\")\n",
        "key = cv2.waitKey(0) # NOTE: if you are using a 64-bit machine, this needs to be: key = cv2.waitKey(0) & 0xFF\n",
        "if key == 27: # wait for the ESC key to exit\n",
        "    cv2.destroyAllWindows()\n",
        "elif key == ord('s'): # wait for 's' key to save and exit\n",
        "    cv2.imwrite('images/dolphin_3.png', img)\n",
        "    cv2.destroyAllWindows()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYo4RYKJAMpd"
      },
      "outputs": [],
      "source": [
        "# write an image with imwrite\n",
        "where_to_save = 'images/dolphin_2.png'\n",
        "cv2.imwrite(where_to_save, img)\n",
        "\n",
        "print('Image saved as {}'.format(where_to_save))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "reading_displaying_and_saving_images.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}